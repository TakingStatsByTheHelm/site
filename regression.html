<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Taking Stats by the Helm</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="A Forum for Understanding Statistics">
  <meta name="generator" content="bookdown 0.1 and GitBook 2.6.7">

  <meta property="og:title" content="Taking Stats by the Helm" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A Forum for Understanding Statistics" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Taking Stats by the Helm" />
  
  <meta name="twitter:description" content="A Forum for Understanding Statistics" />
  

<meta name="author" content="Jonathan Lee Helm">


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="anova.html">
<link rel="next" href="multilevel-models.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Forum for Understanding Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome</a></li>
<li class="chapter" data-level="2" data-path="notation.html"><a href="notation.html"><i class="fa fa-check"></i><b>2</b> Notation</a></li>
<li class="chapter" data-level="3" data-path="t-tests.html"><a href="t-tests.html"><i class="fa fa-check"></i><b>3</b> <em>t</em>-tests</a></li>
<li class="chapter" data-level="4" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>4</b> ANOVA</a></li>
<li class="chapter" data-level="5" data-path="Regression.html"><a href="Regression.html"><i class="fa fa-check"></i><b>5</b> Regression</a><ul>
<li class="chapter" data-level="5.1" data-path="Regression.html"><a href="Regression.html#read-in-the-data"><i class="fa fa-check"></i><b>5.1</b> Read in the Data</a></li>
<li class="chapter" data-level="5.2" data-path="Regression.html"><a href="Regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>5.2</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="5.3" data-path="Regression.html"><a href="Regression.html#confidence-intervals-for-regression-coefficients"><i class="fa fa-check"></i><b>5.3</b> Confidence Intervals for Regression Coefficients</a></li>
<li class="chapter" data-level="5.4" data-path="Regression.html"><a href="Regression.html#confidence-intervals-for-predicted-values"><i class="fa fa-check"></i><b>5.4</b> Confidence Intervals for Predicted values</a></li>
<li class="chapter" data-level="5.5" data-path="Regression.html"><a href="Regression.html#mean-centering"><i class="fa fa-check"></i><b>5.5</b> Mean Centering</a></li>
<li class="chapter" data-level="5.6" data-path="Regression.html"><a href="Regression.html#multiple-regression"><i class="fa fa-check"></i><b>5.6</b> Multiple Regression</a></li>
<li class="chapter" data-level="5.7" data-path="Regression.html"><a href="Regression.html#interaction"><i class="fa fa-check"></i><b>5.7</b> Interaction</a></li>
<li class="chapter" data-level="5.8" data-path="Regression.html"><a href="Regression.html#matrix-notation-and-regression"><i class="fa fa-check"></i><b>5.8</b> Matrix Notation and Regression</a></li>
<li class="chapter" data-level="5.9" data-path="Regression.html"><a href="Regression.html#summary"><i class="fa fa-check"></i><b>5.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>6</b> Multilevel Models</a></li>
<li class="chapter" data-level="7" data-path="structural-equation-models.html"><a href="structural-equation-models.html"><i class="fa fa-check"></i><b>7</b> Structural Equation Models</a></li>
<li class="divider"></li>
<li><a href="https://TakingStatsByTheHelm.github.io/site" target="blank">Maintained by Jonathan Lee Helm</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Taking Stats by the Helm</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Regression" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Regression</h1>
<p>There are three data sets on github: ‘edu_data.csv’, ‘GRE_data.csv’, and ‘salary_data.csv’. We will give all examples using the ‘edu_data.csv’ file, and you can choose to use either the ‘GRE_data.csv’ or ‘salary_data.csv’ to perform your own analyses.</p>
<p>There are descriptions of all three data sets on github. Choose one that seems interesting to work with.</p>
<p>This chapter will cover estimation of the linear regression coefficients, <span class="math inline">\(R^2\)</span>, significance testing of the regression coefficients, significance testing of <span class="math inline">\(R^2\)</span>, and confidence intervals for the linear regression coefficients. We show examples using the ‘edu_data.csv’ data set, and then you will have the opportunity to cover the same material with your own data set. As always, the first step is to read your data into R.</p>
<div id="read-in-the-data" class="section level2">
<h2><span class="header-section-number">5.1</span> Read in the Data</h2>
<p>We will use the get_url() and read.csv() functions to read the education data from github into R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(RCurl)</code></pre></div>
<pre><code>## Loading required package: bitops</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_url =<span class="st"> </span><span class="kw">getURL</span>(<span class="st">&#39;https://raw.githubusercontent.com/TakingStatsByTheHelm/Book/1.-Data-Sets/edu_data.csv&#39;</span>)
edu_data =<span class="st"> </span><span class="kw">read.csv</span>(<span class="dt">text =</span> data_url)</code></pre></div>
</div>
<div id="simple-linear-regression" class="section level2">
<h2><span class="header-section-number">5.2</span> Simple Linear Regression</h2>
<p>Let’s run a simple linear regression! The lm() function will allow us to run intercept-only, simple, and multiple linear regression (remember that multiple linear regression is when we have more that one predictor, and that we’ll talk more about it next week).</p>
<p>Let’s start with an intercept-only model. We’ll use variable ‘api00’ as the outcome variable, which is jsut academic performance for each school during the year 2000.</p>
<p><span class="math display">\[ api00_i = b_0 + \epsilon_i \]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">### Create the object model.01 to store the output. Don&#39;t forget to use &#39;na.action = na.exclude&#39; to remove missing data!

model<span class="fl">.01</span> =<span class="st"> </span><span class="kw">lm</span>(api00 ~<span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> edu_data, <span class="dt">na.action =</span> na.exclude)

### Then, we use the summary() function to get the output from the regression model in a clear way

<span class="kw">summary</span>(model<span class="fl">.01</span>)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = api00 ~ 1, data = edu_data, na.action = na.exclude)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -226.66  -91.16   -7.66   97.34  321.34 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  595.660      6.308   94.42   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 112 on 314 degrees of freedom</code></pre>
<p>Note that the intecept is estimated as 595.660, has a standard error (i.e., <span class="math inline">\(s_{b_0}\)</span>) of 6.308, a <em>t</em>-value of 94.42 <span class="math inline">\(\left(\frac{595.660}{6.308}\right)\)</span>, and corresponding <em>p</em>-value of 0 (i.e., 2 to the negative <span class="math inline">\(16^{th}\)</span> equals 0 in R).</p>
<p>Next, we’ll use the variable ‘meals’ to predict ‘api00’. You’ll just use the lm() and summary() functions again! Don’t forget the ‘na.action = na.exclude’ to remove missing data.</p>
<p><span class="math display">\[ api00_i = b_0 + b_1 \cdot meals_i + \epsilon_i \]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">### Create the object model.02 to store the output to

model<span class="fl">.02</span> =<span class="st"> </span><span class="kw">lm</span>(api00 ~<span class="st"> </span><span class="dv">1</span> +<span class="st"> </span>meals, <span class="dt">data =</span> edu_data, <span class="dt">na.action =</span> na.exclude)

### Then, we use the summary() function to get the output from the regression model in a clear way

<span class="kw">summary</span>(model<span class="fl">.02</span>)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = api00 ~ 1 + meals, data = edu_data, na.action = na.exclude)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -198.351  -46.467   -6.925   47.176  192.169 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 866.4821    11.3087   76.62   &lt;2e-16 ***
## meals        -3.7617     0.1488  -25.28   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 64.3 on 313 degrees of freedom
## Multiple R-squared:  0.6713, Adjusted R-squared:  0.6702 
## F-statistic: 639.1 on 1 and 313 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Notice that we get back estimates for both <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>. In this case our <span class="math inline">\(b_0\)</span> is 866.48, and our <span class="math inline">\(b_1\)</span> is -3.76. Both are significantly different from 0.</p>
<p>Remember, the variable ‘meals’ indicates the percentage of students within a school that receive free meals.</p>
<p>Therefore, these results suggest that for each 1-percentage increase of students meals within a school, we expect a 3.76 point decrease in the school’s overall academic performance (interpretation of <span class="math inline">\(b_1\)</span>). Also, if 0 percent of the students obtain free meals, then we expect the school’s academic performance to equal 866.48 (interpretation of <span class="math inline">\(b_0\)</span>).</p>
<p>If we look toward the bottom of the output, we notice that the estimate of <span class="math inline">\(R^2\)</span> is .67, which indicates that 67% of the variability in academic performace is accounted for the by the percentage of students that receive free meals.</p>
<p>Also note that the <span class="math inline">\(R^2\)</span> value is significantly different from 0.</p>
</div>
<div id="confidence-intervals-for-regression-coefficients" class="section level2">
<h2><span class="header-section-number">5.3</span> Confidence Intervals for Regression Coefficients</h2>
<p>To calculate confidence intervals for the regression coefficients, just use the confint() function</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(model<span class="fl">.02</span>)</code></pre></div>
<pre><code>##                  2.5 %     97.5 %
## (Intercept) 844.231409 888.732875
## meals        -4.054522  -3.468969</code></pre>
<p>By default, the confint() function will calculate 95% confidence intervals.</p>
<p>Note that the 95% confidence interval for <span class="math inline">\(b_0\)</span> is <span class="math inline">\([844.23, 888.73]\)</span>, and the 95% confidence interval for <span class="math inline">\(b_1\)</span> is <span class="math inline">\([-4.05, -3.47]\)</span>.</p>
<p>Therefore, if we were able to repeat this experiment (i.e. collect academic performance and percentage of meals on 315 randomly sample schools, over and over again), we would expect 95% of the <span class="math inline">\(b_0\)</span> to be within <span class="math inline">\([844.32, 888.73]\)</span>, and 95% of the <span class="math inline">\(b_1\)</span> to be within <span class="math inline">\([-4.05, -3.47]\)</span>.</p>
</div>
<div id="confidence-intervals-for-predicted-values" class="section level2">
<h2><span class="header-section-number">5.4</span> Confidence Intervals for Predicted values</h2>
<p>To calculate confidence intervals for predicted values, use the predict() function. We need to tell the predict function the model we are using to predict from (in this case ‘model.02’), the value for <span class="math inline">\(X^*\)</span> (in this case 10).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Follow this same order in the function. Put the model first, then the &#39;newdata = &#39; (but be sure to change the variable name to the one in your model, not meals!), and use &quot;interval = &#39;confidence&#39;&quot;</span>
<span class="kw">predict</span>(model<span class="fl">.02</span>, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">meals =</span> <span class="dv">10</span>), <span class="dt">interval =</span> <span class="st">&#39;confidence&#39;</span>)</code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 828.8647 809.3648 848.3645</code></pre>
<p>Therefore, when a school has 10% of students receiving free meals, we expect that school to have an academic performace of 828.86, and (if we were to repeat this experment over and over) 95% of the time the expected value will be within <span class="math inline">\([809.36, 848.36]\)</span>.</p>
</div>
<div id="mean-centering" class="section level2">
<h2><span class="header-section-number">5.5</span> Mean Centering</h2>
<p>When we perform multiple regression, it is best to mean-center the predictors so that the intercept has more meaning. Let’s begin by mean centering the % of meals and enrollment.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">edu_data$meals_c =<span class="st"> </span>edu_data$meals -<span class="st"> </span><span class="kw">mean</span>(edu_data$meals, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)

edu_data$enroll_c =<span class="st"> </span>edu_data$enroll -<span class="st"> </span><span class="kw">mean</span>(edu_data$enroll, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>Now that we have mean-centered the predictors that we are interested in, we can use them as predictors within multiple regression!</p>
</div>
<div id="multiple-regression" class="section level2">
<h2><span class="header-section-number">5.6</span> Multiple Regression</h2>
<p>Let’s run a multiple regression! The lm() function will allow us to run multiple linear regression (remember last week we used lm() to calculate intercept-only and simple linear regression).</p>
<p>We’ll use variable ‘api00’ as the outcome variable, which is jsut academic performance for each school during the year 2000, and we’ll predict it using the centered enrollemtn and the centered % of meals.</p>
<p>To keep the notation consistent with class, let’s define</p>
<p><span class="math inline">\(X_{1i} = enroll_i\)</span> and <span class="math inline">\(X_{2i} = meals_i\)</span></p>
<p>Then,</p>
<p><span class="math inline">\(x_{1i} = X_{1i} - \bar{X}_{1}\)</span></p>
<p><span class="math inline">\(x_{2i} = X_{2i} - \bar{X}_{2}\)</span></p>
<p><span class="math display">\[ api00_i = b_0 + b_1\cdot x_{1i} + b_2\cdot x_{2i} + \epsilon_i \]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">### Create the object model.01 to store the output. Don&#39;t forget to use &#39;na.action = na.exclude&#39; to remove missing data!

model<span class="fl">.01</span> =<span class="st"> </span><span class="kw">lm</span>(api00 ~<span class="st"> </span><span class="dv">1</span> +<span class="st"> </span>enroll_c +<span class="st"> </span>meals_c , <span class="dt">data =</span> edu_data, <span class="dt">na.action =</span> na.exclude)

### Then, we use the summary() function to get the output from the regression model in a clear way

<span class="kw">summary</span>(model<span class="fl">.01</span>)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = api00 ~ 1 + enroll_c + meals_c, data = edu_data, 
##     na.action = na.exclude)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -205.230  -42.477   -8.259   40.875  164.567 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 595.66032    3.49147  170.60  &lt; 2e-16 ***
## enroll_c     -0.07911    0.01582   -5.00  9.6e-07 ***
## meals_c      -3.49017    0.15335  -22.76  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 61.97 on 312 degrees of freedom
## Multiple R-squared:  0.6956, Adjusted R-squared:  0.6937 
## F-statistic: 356.5 on 2 and 312 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We also get estimates of the intercept and slopes, their standard errors, <em>t</em>-values, and corresponding <em>p</em>-values.</p>
<p>The intercept <span class="math inline">\(b_0\)</span> indicates the expected academic performance for a school with average enrollment and average % of free meals.</p>
<p>The slope <span class="math inline">\(b_1\)</span> indicates that for each student enrolled at the school, we expected a 0.08 decrease in academic performance. The slope <span class="math inline">\(b_2\)</span> indicates for each % of students receiving free meals, we expect a 3.49 decrease in academic performance. We also note that both predictors are significantly different from 0.</p>
</div>
<div id="interaction" class="section level2">
<h2><span class="header-section-number">5.7</span> Interaction</h2>
<p>Let’s run a multiple regression with an interaction term! The lm() function will allow us to run multiple linear regression with interactions.</p>
<p>We’ll use variable ‘api00’ as the outcome variable, which is jsut academic performance for each school during the year 2000, and we’ll predict it using the centered enrollment, centered % of meals, and the interaction.</p>
<p>To keep the notation consistent with class, let’s define</p>
<p><span class="math inline">\(X_{1i} = enroll_i\)</span> and <span class="math inline">\(X_{2i} = meals_i\)</span></p>
<p>Then,</p>
<p><span class="math inline">\(x_{1i} = X_{1i} - \bar{X}_{1}\)</span></p>
<p><span class="math inline">\(x_{2i} = X_{2i} - \bar{X}_{2}\)</span></p>
<p>So we have the model</p>
<p><span class="math display">\[ api00_i = b_0 + b_1\cdot x_{1i} + b_2\cdot x_{2i} + b_3\cdot x_{1i} \cdot x_{2i} + \epsilon_i \]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">### Create the object model.01 to store the output. Don&#39;t forget to use &#39;na.action = na.exclude&#39; to remove missing  data!

<span class="co"># Form the interaction using the I() function</span>
model<span class="fl">.02</span> =<span class="st"> </span><span class="kw">lm</span>(api00 ~<span class="st"> </span><span class="dv">1</span> +<span class="st"> </span>enroll_c +<span class="st"> </span>meals_c +<span class="st"> </span><span class="kw">I</span>(enroll_c*meals_c), <span class="dt">data =</span> edu_data, <span class="dt">na.action =</span> na.exclude)

### Then, we use the summary() function to get the output from the regression model in a clear way

<span class="kw">summary</span>(model<span class="fl">.02</span>)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = api00 ~ 1 + enroll_c + meals_c + I(enroll_c * meals_c), 
##     data = edu_data, na.action = na.exclude)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -207.075  -42.555   -5.186   41.436  157.940 
## 
## Coefficients:
##                         Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)            5.987e+02  3.810e+00 157.154  &lt; 2e-16 ***
## enroll_c              -6.170e-02  1.806e-02  -3.417 0.000717 ***
## meals_c               -3.573e+00  1.583e-01 -22.573  &lt; 2e-16 ***
## I(enroll_c * meals_c) -1.513e-03  7.671e-04  -1.972 0.049490 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 61.68 on 311 degrees of freedom
## Multiple R-squared:  0.6994, Adjusted R-squared:  0.6965 
## F-statistic: 241.2 on 3 and 311 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We can choose either enrollment or meals as the moderator variable. Let’s choose meals, then we rewrite the equation</p>
<p><span class="math display">\[ api00_i = b_0 + b_1\cdot x_{1i} + b_2\cdot x_{2i} + b_3\cdot x_{1i} \cdot x_{2i} + \epsilon_i \]</span></p>
<p>as</p>
<p><span class="math display">\[ api00_i = (b_0 + b_2\cdot x_{2i}) + (b_1 + b_3 \cdot x_{2i})\cdot x_{1i} + \epsilon_i \]</span></p>
<p>Then we have</p>
<p><span class="math display">\[ a_0 = b_0 + b_2\cdot x_{2i} \]</span> <span class="math display">\[ a_1 = b_1 + b_3 \cdot x_{2i} \]</span></p>
<p>and</p>
<p><span class="math display">\[ api00_i = a_0 + a_1\cdot x_{1i} + \epsilon_i \]</span></p>
<p>Filling in these equations based on the output gives us</p>
<p><span class="math display">\[ a_0 = 598.7 - 3.57\cdot x_{2i} \]</span> <span class="math display">\[ a_1 = -.06 - .002 \cdot x_{2i} \]</span></p>
<p>and</p>
<p><span class="math display">\[ api00_i = a_0 + a_1\cdot x_{1i} + \epsilon_i \]</span></p>
<p>Therefore, we have a relation between <span class="math inline">\(x_{1i}\)</span> and <span class="math inline">\(api00_i\)</span>, and that relation changes as a function of <span class="math inline">\(x_{2i}\)</span></p>
</div>
<div id="matrix-notation-and-regression" class="section level2">
<h2><span class="header-section-number">5.8</span> Matrix Notation and Regression</h2>
<p>Let’s begin by noticing that <span class="math inline">\(y_i\)</span> can be written as a column vector. More specifically, if we have <span class="math inline">\(N\)</span> individuals within our sample, then <span class="math display">\[ y_i = \left[ \begin{array}{c}
y_1 \\
y_2 \\
\vdots \\
y_N \end{array} \right] \]</span></p>
<p>Ok, then we can write the intercept-only regression model as</p>
<p><span class="math display">\[ y_i = b_0 + \epsilon_i\]</span> or we can write it in matrix notation as</p>
<p><span class="math display">\[ \left[ \begin{array}{c}
y_1 \\
y_2 \\
\vdots \\
y_N \end{array} \right]  = 
\left[ \begin{array}{c}
1 \\
1 \\
\vdots \\
1 \end{array} \right] [b_0] + 
\left[ \begin{array}{c}
\epsilon_1 \\
\epsilon_2 \\
\vdots \\
\epsilon_N \end{array} \right]\]</span></p>
<p>Now, let’s extend this equation to include a single predictor. In particular, if we have</p>
<p><span class="math display">\[ y_i = b_0 + b_1(x_{1i})  + \epsilon_i \]</span></p>
<p>then we can rewrite equation in matrix notation as</p>
<p><span class="math display">\[ \left[ \begin{array}{c}
y_1 \\
y_2 \\
\vdots \\
y_N \end{array} \right]  = 
\left[ \begin{array}{cc}
1, x_{11}\\
1, x_{12}\\
\vdots \\
1, x_{1N}\end{array} \right]
\left[ \begin{array}{c}b_0\\ b_1\end{array}\right] + 
\left[ \begin{array}{c}
\epsilon_1 \\
\epsilon_2 \\
\vdots \\
\epsilon_N \end{array} \right]\]</span></p>
<p>Finally, extending the equation that contains <span class="math inline">\(q\)</span> predictor variables, we have <span class="math display">\[ y_i = b_0 + b_1(x_{1i}) + b_2(x_{2i}) + ... + b_q(x_{qi}) + \epsilon_i \]</span></p>
<p>which is written in matrix notation as</p>
<p><span class="math display">\[ \left[ \begin{array}{c}
y_1 \\
y_2 \\
\vdots \\
y_N \end{array} \right]  = 
\left[ \begin{array}{cccc}
1, x_{11}, \ldots, x_{q1}\\
1, x_{12}, \ldots, x_{q2}\\
\vdots \\
1, x_{1N}, \ldots, x_{qN}\end{array} \right]
\left[ \begin{array}{c}b_0\\ b_1\\ \vdots\\ b_q\end{array}\right] + 
\left[ \begin{array}{c}
\epsilon_1 \\
\epsilon_2 \\
\vdots \\
\epsilon_N \end{array} \right]\]</span></p>
<p>When we implement this model within R, it is important to know that we call on <span class="math inline">\(y_i\)</span> and <span class="math inline">\({x_{1}, ..., x_{q}}\)</span> as variables within a data frame. We’ll emphasize this within the examples to come. Ok, now let’s simplify the notation a bit more. Let’s define</p>
<p><span class="math display">\[ \boldsymbol{Y} = \left[ \begin{array}{c}
y_1 \\
y_2 \\
\vdots \\
y_N \end{array} \right] ;\boldsymbol{X} = \left[ \begin{array}{cccc}
1, x_{11}, \ldots, x_{q1}\\
1, x_{12}, \ldots, x_{q2}\\
\vdots \\
1, x_{1N}, \ldots, x_{qN}\end{array} \right]; \boldsymbol{b} = \left[ \begin{array}{c}b_0\\ b_1\\ \vdots\\ b_q\end{array}\right]; \boldsymbol{\epsilon} = \left[ \begin{array}{c}
\epsilon_1 \\
\epsilon_2 \\
\vdots \\
\epsilon_N \end{array} \right] \]</span></p>
<p>Then, the regression model may be compactly written as</p>
<p><span class="math display">\[ \boldsymbol{Y} = \boldsymbol{X}\boldsymbol{b} + \boldsymbol{\epsilon} \]</span></p>
<p>Finally, we would like to solve for <span class="math inline">\(\boldsymbol{b}\)</span>. Those are the focal parameter estimates. First begin by premultiplying both sides of the equation by <span class="math inline">\(\boldsymbol{X&#39;}\)</span></p>
<p><span class="math display">\[ \boldsymbol{X&#39;}\boldsymbol{Y} = \boldsymbol{X&#39;}\boldsymbol{X}\boldsymbol{b} \]</span></p>
<p>Then premultiply both sides by <span class="math inline">\(\left(\boldsymbol{X&#39;}\boldsymbol{X}\right)^{-1}\)</span></p>
<p><span class="math display">\[ \left(\boldsymbol{X&#39;}\boldsymbol{X}\right)^{-1}\boldsymbol{X&#39;}\boldsymbol{Y} = \left(\boldsymbol{X&#39;}\boldsymbol{X}\right)^{-1}\boldsymbol{X&#39;}\boldsymbol{X}\boldsymbol{b} \]</span></p>
<p>which simpifies to <span class="math display">\[ \left(\boldsymbol{X&#39;}\boldsymbol{X}\right)^{-1}\boldsymbol{X&#39;}\boldsymbol{Y} = \boldsymbol{b} \]</span></p>
<p>Therefore, we can easily calculate the estimates of the parameters using matrix algebra! And this form of matrix manipulation is, quite literally, what the computer program is performing to estimate a the parameters within a multiple regression.</p>
</div>
<div id="summary" class="section level2">
<h2><span class="header-section-number">5.9</span> Summary</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="anova.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multilevel-models.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://TakingStatsByTheHelm.github.io/site04-Regression.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
